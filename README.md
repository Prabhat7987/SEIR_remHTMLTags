# ğŸŒ Page Info Extractor (Python CLI Web Scraper)

A lightweight **Command Line Web Scraper** built using Python that fetches and extracts useful information from any webpage.

This tool downloads a webpage and displays:

âœ” Page Title
âœ” Full visible text content
âœ” All hyperlinks present on the page

---

##ğŸ˜ƒ Features
ğŸ‘‰Fetch webpage using HTTP requests
ğŸ‘‰Parse HTML content efficiently
ğŸ‘‰Extract page title
ğŸ‘‰Extract clean readable text (without HTML tags)
ğŸ‘‰Extract all links (`<a href="">`)
ğŸ‘‰Command-line interface support
ğŸ‘‰Beginner-friendly and easy to extend

---

## ğŸ›  Technologies Used
* **Python**
* **Requests** â†’ for HTTP requests
* **BeautifulSoup (bs4)** â†’ for HTML parsing
* **sys module** â†’ for command-line arguments

---

## ğŸ“‚ Project Structure
```
page_info.py   # Main script
README.md      # Documentation
```

---

## âš™ï¸ Installation
### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/yourusername/page-info-extractor.git
cd page-info-extractor
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install requests beautifulsoup4
```

## â–¶ï¸ Usage
Run the script from terminal:
```bash
python page_info.py <URL>
```

### âœ… Example
```bash
python page_info.py https://example.com
```

## ğŸ§¾ Example Output
```
PAGE TITLE:
Example Domain

PAGE BODY:
Example Domain This domain is for use in illustrative examples...

PAGE LINKS:
https://www.iana.org/domains/example
```

## ğŸ§  How It Works
### 1ï¸âƒ£ Command-line Argument
The script reads the URL using:
```python
sys.argv
```

### 2ï¸âƒ£ Fetch Webpage
The `requests` library sends an HTTP GET request:
```python
requests.get(url)
```

This retrieves the webpage HTML.

### 3ï¸âƒ£ Parse HTML
BeautifulSoup converts raw HTML into a searchable structure:
```python
BeautifulSoup(html, "html.parser")
```

### 4ï¸âƒ£ Extract Data
âœ” Title â†’ `<title>` tag
âœ” Body text â†’ visible page content
âœ” Links â†’ `<a href="">` tags

## ğŸ“š Concepts Demonstrated
âœ” HTTP Requests & Responses
âœ” HTML Parsing
âœ” Web Scraping Basics
âœ” Command-line Interfaces
âœ” Python Standard Library Usage

## â— Error Handling
The program checks correct usage:
```bash
Usage: python page_info.py <URL>
```

Prevents crashes when URL is missing.

## ğŸ”® Future Improvements
* [ ] Extract images from webpage
* [ ] Save output to a file
* [ ] Crawl multiple pages
* [ ] Filter internal vs external links
* [ ] Add user-agent headers
* [ ] Build GUI version

---

## ğŸ¤ Contributing
Contributions are welcome!
Feel free to fork this repo and improve it.

---

## ğŸ‘¨â€ğŸ’» Author
**Prabhat Patidar**
Python & Web Development Learner ğŸš€


